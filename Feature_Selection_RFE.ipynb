{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jIObX9eOpxva"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (8, 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcDO9Qm8pxvc"
      },
      "source": [
        "## Selecting features for model performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2YBK-XDpxvc"
      },
      "source": [
        "### Building a diabetes classifier\n",
        "We'll be using the Pima Indians diabetes dataset to predict whether a person has diabetes using logistic regression. There are 8 features and one target in this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7OJ1R4-Jpxvd"
      },
      "outputs": [],
      "source": [
        "diabetes_df = pd.read_csv('/content/diabetes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YjxJJ8rIpxve"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pprint import pprint\n",
        "\n",
        "X, y = diabetes_df.iloc[:, :-1], diabetes_df.iloc[:, -1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "lr = LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mq_TXdb6pxvf",
        "outputId": "5a8bfe91-00d6-49ee-9a91-2f2bfcd24e31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74.0% accuracy on test set.\n",
            "{'Age': 0.11,\n",
            " 'BMI': 0.62,\n",
            " 'BloodPressure': 0.35,\n",
            " 'DiabetesPedigreeFunction': 0.37,\n",
            " 'Glucose': 1.18,\n",
            " 'Insulin': 0.23,\n",
            " 'Pregnancies': 0.52,\n",
            " 'SkinThickness': 0.02}\n"
          ]
        }
      ],
      "source": [
        "# Fit the scaler on the training features and transform these in one go\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "\n",
        "# Fit the logistic regression model on the scaled training data\n",
        "lr.fit(X_train_std, y_train)\n",
        "\n",
        "# Scaler the test features\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Predict diabetes presence on the scaled test set\n",
        "y_pred = lr.predict(X_test_std)\n",
        "\n",
        "# Print accuracy metrics and feature coefficients\n",
        "print(\"{0:.1%} accuracy on test set.\".format(accuracy_score(y_test, y_pred)))\n",
        "pprint(dict(zip(X.columns, abs(lr.coef_[0]).round(2))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8knM1SB1pxvi"
      },
      "source": [
        "We get almost 75% accuracy on the test set. Take a look at the differences in model coefficients for the different features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5p-6_sEpxvn"
      },
      "source": [
        "### Automatic Recursive Feature Elimination\n",
        "Now let's automate the recursive process. We will Wrap a Recursive Feature Eliminator (RFE) around our logistic regression estimator and pass it the desired number of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vV9M6qW6pxvn"
      },
      "outputs": [],
      "source": [
        "X, y = diabetes_df.iloc[:, :-1], diabetes_df.iloc[:, -1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "lr = LogisticRegression()\n",
        "\n",
        "# Fit the scaler on the training features and transform these in one go\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "\n",
        "# Fit the logistic regression model on the scaled training data\n",
        "lr.fit(X_train_std, y_train)\n",
        "\n",
        "# Scaler the test features\n",
        "X_test_std = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IbzjQAprpxvo",
        "outputId": "f936e022-ad43-4ccb-a0ff-50d57897884e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting estimator with 8 features.\n",
            "Fitting estimator with 7 features.\n",
            "Fitting estimator with 6 features.\n",
            "Fitting estimator with 5 features.\n",
            "Fitting estimator with 4 features.\n",
            "{'Pregnancies': 1, 'Glucose': 1, 'BloodPressure': 3, 'SkinThickness': 5, 'Insulin': 6, 'BMI': 1, 'DiabetesPedigreeFunction': 2, 'Age': 4}\n",
            "Index(['Pregnancies', 'Glucose', 'BMI'], dtype='object')\n",
            "80.1% accuracy on test set.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Create the RFE a LogisticRegression estimator and 3 features to select\n",
        "rfe = RFE(estimator=LogisticRegression(), n_features_to_select=3, verbose=1)\n",
        "\n",
        "# Fits the eliminator to the data\n",
        "rfe.fit(X_train_std, y_train)\n",
        "\n",
        "# Print the features and their ranking (high = dropped early on)\n",
        "print(dict(zip(X.columns, rfe.ranking_)))\n",
        "\n",
        "# Print the features that are not elimiated\n",
        "print(X.columns[rfe.support_])\n",
        "\n",
        "# CAlculates the test set accuracy\n",
        "acc = accuracy_score(y_test, rfe.predict(X_test_std))\n",
        "print(\"{0:.1%} accuracy on test set.\".format(acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3yyVz61pxvo"
      },
      "source": [
        "## Tree-based feature selection\n",
        "- Random forest classifier\n",
        "![rf classifier](https://github.com/goodboychan/chans_jupyter/blob/main/_notebooks/image/rfc.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JugsqUGpxvp"
      },
      "source": [
        "### Building a random forest model\n",
        "You'll again work on the Pima Indians dataset to predict whether an individual has diabetes. This time using a random forest classifier. You'll fit the model on the training data after performing the train-test split and consult the feature importance values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "p79hA1sSpxvp",
        "outputId": "99105bd1-935c-4468-e1b4-c78121c0c776",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Age': 0.14,\n",
            " 'BMI': 0.17,\n",
            " 'BloodPressure': 0.09,\n",
            " 'DiabetesPedigreeFunction': 0.13,\n",
            " 'Glucose': 0.24,\n",
            " 'Insulin': 0.08,\n",
            " 'Pregnancies': 0.08,\n",
            " 'SkinThickness': 0.07}\n",
            "77.1% accuracy on test set.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Perform a 75% training and 25% test data split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "# Fit the random forest model to the training data\n",
        "rf = RandomForestClassifier(random_state=0)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Calculate the accuracy\n",
        "acc = accuracy_score(y_test, rf.predict(X_test))\n",
        "\n",
        "# Print the importances per feature\n",
        "pprint(dict(zip(X.columns, rf.feature_importances_.round(2))))\n",
        "\n",
        "# Print accuracy\n",
        "print(\"{0:.1%} accuracy on test set.\".format(acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ranhRNO4pxvq"
      },
      "source": [
        "### Random forest for feature selection\n",
        "Now lets use the fitted random model to select the most important features from our input dataset `X`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ygrdCZg5pxvr",
        "outputId": "98219e42-bb63-4ceb-b39e-67a8be6de9e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False  True False False False  True False False]\n",
            "Index(['Glucose', 'BMI'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Create a mask for features importances above the threshold\n",
        "mask = rf.feature_importances_ > 0.15\n",
        "\n",
        "# Prints out the mask\n",
        "print(mask)\n",
        "\n",
        "# Apply the mask to the feature dataset X\n",
        "reduced_X = X.loc[:, mask]\n",
        "\n",
        "# Prints out the selected column names\n",
        "print(reduced_X.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1sQhOUhpxvr"
      },
      "source": [
        "### Recursive Feature Elimination with random forests\n",
        "You'll wrap a Recursive Feature Eliminator around a random forest model to remove features step by step. This method is more conservative compared to selecting features after applying a single importance threshold. Since dropping one feature can influence the relative importances of the others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qdkbVodppxvs",
        "outputId": "eceea2d6-e6ca-431e-f636-50372143320e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting estimator with 8 features.\n",
            "Fitting estimator with 7 features.\n",
            "Fitting estimator with 6 features.\n",
            "Fitting estimator with 5 features.\n",
            "Fitting estimator with 4 features.\n",
            "Fitting estimator with 3 features.\n",
            "Index(['Glucose', 'BMI'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Wrap the feature eliminator around the random forest model\n",
        "rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=2, verbose=1)\n",
        "\n",
        "# Fit the model to the training data\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "# Create a mask using an attribute of rfe\n",
        "mask = rfe.support_\n",
        "\n",
        "# Apply the mask to the feature dataset X and print the result\n",
        "reduced_X = X.loc[:, mask]\n",
        "print(reduced_X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HBNAaT3bpxvs",
        "outputId": "4a570a8a-0039-4edc-fe46-7e25ac98c8d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting estimator with 8 features.\n",
            "Fitting estimator with 6 features.\n",
            "Fitting estimator with 4 features.\n",
            "Index(['Glucose', 'BMI'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Wrap the feature eliminator around the random forest model\n",
        "rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=2, step=2, verbose=1)\n",
        "\n",
        "# Fit the model to the training data\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "# Create a mask using an attribute of rfe\n",
        "mask = rfe.support_\n",
        "\n",
        "# Apply the mask to the feature dataset X and print the result\n",
        "reduced_X = X.loc[:, mask]\n",
        "print(reduced_X.columns)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}